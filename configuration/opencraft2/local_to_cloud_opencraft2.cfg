[infrastructure]
provider = gcp
infra_only = False

# GCP details
gcp_region = "europe-central2"
gcp_zone = "europe-central2-c"
gcp_project = "opencraft2"
gcp_credentials = "/home/jei/.ssh/opencraft2-aeae26ff1e3c.json"

# Endpoint VM details
endpoint_nodes  = 2
# n1-standard-2 = 2vCPU, 7.5GB RAM, GPU
# n1-standard-4 = 4vCPU, 15GB RAM, GPU
# n1-standard-8 = 8vCPU, 30GB RAM, GPU
gcp_endpoint    = "n1-standard-4"
use_gpu_endpoint = True
endpoint_cores = 4
endpoint_memory = 15
endpoint_quota = 1

# Cloud VM details
cloud_nodes    = 2
# 4vCPU, 16GB RAM, no GPU
gcp_cloud      = "e2-standard-4"
use_gpu_cloud = False
cloud_cores = 4
cloud_memory = 16
cloud_quota = 1

base_path = /mnt/sdb/jei/

# Don't delete VMs after running
delete = False

# Network settings between endpoints and cloud
network_emulation = False
# Endpoint to cloud
#cloud_endpoint_latency_avg = 20 
#cloud_endpoint_latency_var = 5  
#cloud_endpoint_throughput = 15
# Endpoint to endpoint
#endpoint_latency_avg = 7.5
#endpoint_latency_var = 2.5     
#endpoint_throughput = 1000

[benchmark]
resource_manager = kubernetes

docker_pull = True

install_docker_endpoint = False

application = opencraft2
experiment_duration = 180

# Only run 1 server in cloud
applications_per_worker = 1
# Number of clients per endpoint node
applications_per_endpoint = 1
# What percent of application will run in streamed client mode
streamed_client_ratio = 0
# What deployment configuration to use
deployment_config = "LocalToStream.json"

# CPU (in cores) and memory (in GB) per application for the cloud/edge worker
application_worker_cpu = 2.0      
application_worker_memory = 8.0 

# list of cpu percents by application
opencraft_endpoint_cpu = 4.0,4.0
#application_endpoint_cpu = 1.5    
application_endpoint_memory = 8.0

# Grafana/Prometheseus, don't bother for these tests
observability = False